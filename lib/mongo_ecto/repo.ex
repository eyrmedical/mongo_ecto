defmodule MongoEcto.Repo do
    @moduledoc """
    Define Repo-like functions to import in Mongo models.
    """

    require Logger

    alias Ecto.Changeset

    @type mongo_bson_id :: %BSON.ObjectId{}
    @type mongo_string_id :: << _ :: 192 >> 
    @type mongo_binary_id :: << _ :: 96 >>
    @type mongo_id :: mongo_string_id | mongo_binary_id | mongo_bson_id | String.t | integer
    @type mongo_object_result :: {:ok, Ecto.Schema.t} | {:error, Ecto.Changeset.t}
    @type mongo_changeset :: Ecto.Changeset.t
    @type mongo_record :: Ecto.Schema.t
    @type mongo_dirty_record :: Ecto.Schema.t
    @type mongo_object :: mongo_changeset | mongo_record
    @type mongo_query :: map()
    @type mongo_options :: Keyword.t
    @type mongo_preload :: [atom()]
    @type mongo_schema :: Ecto.Schema.t
    @type mongo_assoc :: %Ecto.Association.HasThrough{} | %Ecto.Association.Has{}
    @type mongo_datatype :: mongo_bson_id | %BSON.DateTime{}


    def start_link(opts) do
        MongoEcto.start(opts)
    end
    @doc """
    Get all records by query.
    """
    @spec all(mongo_schema, mongo_query) :: [mongo_record] | []
    def all(schema, query \\ %{}) do
        all(schema, query, [])
    end
    @spec all(mongo_schema, mongo_query, mongo_options) :: [mongo_record] | []
    def all(schema, query, options) do
        all(schema, query, options, [])
    end
    @spec all(mongo_schema, mongo_query, mongo_options, mongo_preload) :: [mongo_record] | []
    def all(schema, query, options, preload) do
        mongo_raw_data = query(schema, query, options)
        Enum.map(mongo_raw_data, &(cursor_record_to_struct(schema, &1, preload)))
    end


    @doc """
    Get record by id.
    """
    @spec get(mongo_schema, mongo_id) :: mongo_record | nil | no_return
    def get(_schema, nil), do: nil
    def get(schema, id) do
        id = if is_mongo_id(id), do: to_mongo_id(id), else: id
        with [key] <- schema.__schema__(:primary_key),
            {:is_id?, _, true} <- {:is_id?, key, key == :id}
        do
            get_by(schema, %{_id: id})
        else
            {:is_id?, key, false} ->
                get_by(schema, Map.put(%{}, key, id))
            _ ->
                raise Ecto.InvalidMongoIdError
        end
    end


    @doc """
    Get record by id, raise if not found.
    """
    @spec get!(mongo_schema, mongo_id) :: mongo_record | no_return
    def get!(_schema, nil), do: raise %Ecto.NoResultsError{message: "no results found"}
    def get!(schema, id) do
        raise_if_no_results schema, get(schema, id)
    end


    @doc """
    Get record by query.
    """
    @spec get_by(mongo_schema, mongo_query) :: mongo_record | nil | no_return
    def get_by(schema, query \\ %{}) do
        result = all(schema, query)
        case result do
            [record | _] -> record
            _ -> nil
        end
    end


    @doc """
    Get record by query, raise if not found.
    """
    @spec get_by!(mongo_schema, mongo_query) :: mongo_record | no_return
    def get_by!(schema, query \\ %{}) do
        raise_if_no_results schema, get_by(schema, query)
    end


    @doc """
    Get single record by query.
    """
    @spec one(mongo_schema, mongo_query) :: mongo_record | nil | no_return
    def one(schema, query \\ %{}) do
        result = all(schema, query)
        case result do
            [record | []] -> record
            [_record | _] -> raise(Ecto.MultipleResultsError, message: "expected one record, but got more")
            _ -> nil
        end
    end


    @doc """
    Get single record by query, raise if not found.
    """
    @spec one!(mongo_schema, mongo_query) :: mongo_record | no_return
    def one!(schema, query \\ %{}) do
        raise_if_no_results schema, one(schema, query)
    end


    @doc """
    Add new record.
    """
    @spec insert(mongo_object) :: {:ok, mongo_record} | {:error, mongo_changeset}
    def insert(%Changeset{valid?: true, data: %{__struct__: schema}} = changeset) do
        new_record = changeset
        |> autogenerate(:autogenerate)
        |> schema.apply_changes

        foreign_keys = get_foreign_keys(new_record)
        new_record_map = Map.from_struct(new_record)
        |> convert_types_with(&to_mongo_type/1)
        |> convert_types_for(foreign_keys, &to_mongo_id/1)
        |> convert_embeds(schema.__schema__(:embeds))

        result = Mongo.insert_one(MongoEcto, schema.collection_name, new_record_map)
        case result do
            {:ok, %{inserted_id: bson_id}} ->
                inserted_record = add_autogenerated_field(schema, new_record, mongo_id_to_string(bson_id))
                {:ok, inserted_record}
            {:error, mongo_error} ->
                Logger.error fn -> "Mongo Insert Error: " <> inspect(mongo_error) end
                changeset = Changeset.add_error(changeset, get_primary_error_field(schema), "failed to create new record")
                {:error, changeset}
            _ ->
                {:ok, new_record}
        end
    end
    def insert(%Changeset{valid?: false} = changeset) do
        {:error, changeset}
    end
    def insert(record) do
        changeset = Changeset.change(record)
        insert(changeset)
    end


    @doc """
    Add new record, raise in case of error.
    """
    @spec insert!(mongo_object) :: mongo_record | no_return
    def insert!(changeset) do
        raise_if_changeset_errors insert(changeset), "insert"
    end


    @doc """
    Update existing record.
    """
    @spec update(mongo_changeset) :: {:ok, mongo_record} | {:error, mongo_changeset}
    def update(%Changeset{valid?: true, data: %{__struct__: schema} = record} = changeset) do
        record_to_update = changeset
        |> autogenerate(:autoupdate)
        |> schema.apply_changes

        foreign_keys = get_foreign_keys(record_to_update)
        to_update = Map.from_struct(record_to_update)
        |> convert_types_with(&to_mongo_type/1)
        |> convert_types_for(foreign_keys, &to_mongo_id/1)
        |> convert_embeds(schema.__schema__(:embeds))

        result = Mongo.replace_one(
            MongoEcto,
            schema.collection_name,
            get_record_query(record),
            to_update
        )
        case result do
            {:ok, %Mongo.UpdateResult{matched_count: 1, modified_count: 1, upserted_id: nil}} ->
                updated_record = add_autogenerated_field(schema, record_to_update, record)
                {:ok, updated_record}
            {:error, mongo_error} ->
                Logger.error fn -> "Mongo Update Error: " <> inspect(mongo_error) end
                changeset = Changeset.add_error(changeset, get_primary_error_field(schema), "failed to update existing record")
                {:error, changeset}
            _ ->
                updated_record = add_autogenerated_field(schema, record_to_update, record)
                {:ok, updated_record}
        end
    end
    def update(%Changeset{valid?: false} = changeset) do
        {:error, changeset}
    end
    def update(%Changeset{data: %{__struct__: schema}} = _changeset) do
        raise Ecto.NoPrimaryKeyFieldError, schema: schema
    end


    @doc """
    Update existing record, raise in case of error.
    """
    @spec update!(mongo_changeset) :: mongo_record | no_return
    def update!(%Changeset{} = changeset) do
        raise_if_changeset_errors update(changeset), "update"
    end


    @doc """
    Update existing record.
    """
    @spec insert_or_update(mongo_changeset) :: {:ok, mongo_record} | {:error, mongo_changeset}
    def insert_or_update(%Changeset{valid?: true, data: %{id: record_id}} = changeset)
        when is_bitstring(record_id) do
        update(changeset)
    end
    def insert_or_update(%Changeset{valid?: true} = changeset) do
        insert(changeset)
    end
    def insert_or_update(%Changeset{valid?: false} = changeset) do
        {:error, changeset}
    end


    @doc """
    Update existing record, raise in case of error.
    """
    @spec insert_or_update!(mongo_changeset) :: mongo_record | no_return
    def insert_or_update!(changeset) do
        raise_if_changeset_errors insert_or_update(changeset), "upsert"
    end


    @doc """
    Delete existing record.
    """
    @spec delete(mongo_object) :: {:ok, mongo_record} | {:error, mongo_changeset}
    def delete(%Changeset{data: data}) do
        delete(data)
    end
    def delete(%{__struct__: schema} = record) do
        query = get_record_query(record)
        result = Mongo.delete_one(MongoEcto, schema.collection_name, query)
        case result do
            {:ok, %Mongo.DeleteResult{deleted_count: 1}} -> 
                {:ok, record}
            _ ->
                changeset = record
                |> Changeset.change
                |> Changeset.add_error(get_primary_error_field(schema), "failed to delete record")
                {:error, changeset}
        end
    end


    @doc """
    Delete existing record, raise in case of error.
    """
    @spec delete!(mongo_object) :: mongo_record | no_return
    def delete!(record) do
        raise_if_changeset_errors delete(record), "delete"
    end


    @doc """
    Load connected records from another schema.
    """
    @spec preload(mongo_record | nil, atom() | [atom()]) :: mongo_record
    def preload(nil, _key) do
        nil
    end
    def preload(record, keys) when is_list(keys) do
        Enum.reduce keys, record, &(preload &2, &1)
    end
    def preload(record, key) do
        assoc = record.__struct__.__schema__(:association, key)
        load_assoc(record, assoc)
    end


    @doc """
    Encode binary id to a string value.
    """
    @spec mongo_id_to_string(%BSON.ObjectId{} | binary()) :: String.t
    def mongo_id_to_string(%BSON.ObjectId{value: bson_id}) do
        mongo_id_to_string(bson_id)
    end
    def mongo_id_to_string(<< _ :: size(96)>> = mongo_id) do
        Base.encode16(mongo_id, case: :lower)
    end
    def mongo_id_to_string(mongo_id) when is_bitstring(mongo_id) do
        mongo_id
    end


    # Load HasThrough assoc relationship
    @spec load_assoc(mongo_record, mongo_assoc) :: mongo_record
    defp load_assoc(record, %Ecto.Association.HasThrough{
        cardinality: :many,
        relationship: :child,
        through: [direct_child, direct_grandc]
    }) do
        record = preload(record, direct_child)
        children = Map.get(record, direct_child)
        children = Enum.map children, &(preload(&1, direct_grandc))
        all_grandc = Enum.reduce children, [], fn(child, acc) ->
            grandc = Map.get(child, direct_grandc)
            acc ++ if is_list(grandc), do: grandc, else: [grandc]
        end
        
        record
        |> Map.put(direct_child, children)
        |> Map.put(direct_grandc, all_grandc)
    end
    # Load HasMany assoc relationship
    defp load_assoc(record, %Ecto.Association.Has{
        cardinality: :many,
        relationship: :child,
        field: assoc_field,
        owner_key: parent_key,
        related_key: child_key,
        related: childSchema
    }) do
        query = Map.put(%{}, child_key, Map.get(record, parent_key))
        children = all(childSchema, query)
        Map.put(record, assoc_field, children)
    end
    # Load HasOne assoc relationship
    defp load_assoc(record, %Ecto.Association.Has{
        cardinality: :one,
        relationship: :child,
        field: assoc_field,
        owner_key: parent_key,
        related_key: child_key,
        related: childSchema
    }) do
        query = Map.put(%{}, child_key, Map.get(record, parent_key))
        children = one(childSchema, query)
        Map.put(record, assoc_field, children)
    end
    defp load_assoc(record, %Ecto.Association.BelongsTo{
        cardinality: :one,
        relationship: :parent,
        field: assoc_field,
        owner_key: parent_key,
        related_key: child_key,
        related: parentSchema
    }) do
        query = Map.put(%{}, parent_key, Map.get(record, child_key))
        parent = one(parentSchema, query)
        Map.put(record, assoc_field, parent)
    end
    defp load_assoc(_record, assoc) do
        Logger.error fn ->
            "Mongo Preload Error: association was not implemeneted, yet" <> inspect(assoc)
        end
        raise Ecto.SubQueryError, message: "association was not implemented"
    end
    

    # Convert all changeset errors into a single string value.
    @spec changeset_errors_to_string(mongo_changeset) :: String.t
    defp changeset_errors_to_string(changeset) do
        Ecto.Changeset.traverse_errors(changeset, fn {msg, opts} ->
            Enum.reduce(opts, msg, fn {key, value}, _acc ->
                String.replace(msg, "%{#{key}}", to_string(value))
            end)
        end)
    end


    # Raise Ecto.NoResultsError if there is no results
    @spec raise_if_no_results(mongo_schema, mongo_record | nil) :: mongo_record | no_return
    defp raise_if_no_results(schema, result) do
        case result do
            nil -> raise Ecto.NoResultsError.exception([queryable: schema])
            record -> record
        end
    end


    # Convert changeset errors, by raising Ecto.InvalidChangesetError
    # Useful for bang (!) functions
    @spec raise_if_changeset_errors(mongo_object_result, String.t) :: mongo_object | no_return
    defp raise_if_changeset_errors(result, action) do
        case result do
            {:ok, record} ->
                record
            {:error, changeset} ->
                Logger.error fn ->
                    "Mongo #{action} Error: " <> inspect changeset_errors_to_string(changeset)
                end
                raise Ecto.InvalidChangesetError, [action: action, changeset: changeset]
            _ ->
                raise Ecto.InvalidChangesetError, action: action
        end
    end


    # Generates automatic gereted fields (such as updated_at, inserted_at etc.)
    @spec autogenerate(mongo_changeset, atom()) :: mongo_changeset
    defp autogenerate(%Changeset{data: %{__struct__: schema}, changes: changes} = changeset, action) do
        new_changes = Enum.reduce schema.__schema__(action), changes, fn
            {k, {mod, fun, args}}, acc ->
                Map.put_new(acc, k, apply(mod, fun, args))
        end

        # Support for embedded schemas in main document
        {filtered_changes, updated_changeset} = 
            Enum.reduce schema.__schema__(:embeds), {new_changes, changeset}, fn
                embed_key, {new_changes, changeset} ->
                    if Map.has_key?(new_changes, embed_key) do
                        embed = Map.fetch!(new_changes, embed_key)
                        changeset = Ecto.Changeset.put_embed(changeset, embed_key, embed)
                        {Map.delete(new_changes, embed_key), changeset}
                    else
                        {new_changes, changeset}
                    end
            end

        Ecto.Changeset.change(updated_changeset, filtered_changes)
    end


    # Checks if id is a correct mongo_id type.
    @spec is_mongo_id(mongo_id) :: boolean()
    defp is_mongo_id(id) do
        convertable_to_mongo_id(id) or is_mongo_bson_id(id)
    end


    # Checks if id convertable to BSON.ObjectId.
    @spec convertable_to_mongo_id(mongo_id) :: boolean()
    defp convertable_to_mongo_id(mongo_id) when is_bitstring(mongo_id), do: true
    defp convertable_to_mongo_id(mongo_id) when is_integer(mongo_id), do: true
    defp convertable_to_mongo_id(<< _ :: size(192)>>), do: true
    defp convertable_to_mongo_id(<< _ :: size(96)>>), do: true
    defp convertable_to_mongo_id(_id), do: false


    # Checks if id is a BSON.ObjectId type.
    @spec is_mongo_bson_id(mongo_id) :: boolean()
    defp is_mongo_bson_id(%BSON.ObjectId{} = _id), do: true
    defp is_mongo_bson_id(_id), do: false


    # Ensure that Mongo id is converted to a proper BSON object.
    @spec to_mongo_id(mongo_id) :: mongo_bson_id
    defp to_mongo_id(nil), do: nil
    defp to_mongo_id(%BSON.ObjectId{} = id), do: id
    defp to_mongo_id(<< _ :: size(192)>> = string_id) when is_bitstring(string_id) do
        binary_id = Base.decode16!(string_id, case: :lower)
        to_mongo_id(binary_id)
    end
    defp to_mongo_id(<< _ :: size(96)>> = binary_id) do
        %BSON.ObjectId{value: binary_id}
    end
    defp to_mongo_id(string_id) when is_bitstring(string_id) do
        string_id
    end
    defp to_mongo_id(integer_id) when is_integer(integer_id) do
        integer_id
    end


    # Query mongo for data.
    @spec query(mongo_schema, mongo_query, mongo_options) :: [map()]
    defp query(schema, query, options) do
        mongo_cursor = Mongo.find(MongoEcto, schema.collection_name, normalise_query_map(schema, query), options)
        mongo_cursor
        |> Enum.to_list
    end

    # Normalise query to fit MongoDb.
    @spec normalise_query_map(mongo_schema, mongo_query) :: mongo_query
    defp normalise_query_map(schema, query) do
        Enum.reduce query, %{}, &(normalise_query_chunk(schema, &1, &2))
    end

    # Normalise query chunk.
    @spec normalise_query_chunk(mongo_schema, {atom(), any()}, mongo_query) :: mongo_query
    defp normalise_query_chunk(_schema, {key, %BSON.ObjectId{} = value}, acc) do
        Map.put acc, key, value
    end
    defp normalise_query_chunk(_schema, {key, %{__struct__: _} = value}, acc) do
        Map.put acc, key, value
    end
    defp normalise_query_chunk(schema, {key, value}, acc) when is_map(value) do
        Map.put acc, key, normalise_query_map(schema, value)
    end
    defp normalise_query_chunk(schema, {key, << _ :: size(96)>> = value}, acc) do
        Map.put acc, key, convert_mongo_id_field(schema, key, value)
    end
    defp normalise_query_chunk(schema, {key, << _ :: size(192)>> = value}, acc) do
        Map.put acc, key, convert_mongo_id_field(schema, key, value)
    end
    defp normalise_query_chunk(_schema, {key, value}, acc) do
        Map.put acc, key, value
    end

    # Helper function to convert to valid mongo id's of primary and association keys.
    @spec convert_mongo_id_field(mongo_schema, atom(), any()) :: any()
    defp convert_mongo_id_field(schema, key, value) do
        fields = Enum.reduce schema.__schema__(:types), [], fn({key, value}, acc) ->
            if value === :binary_id, do: [key] ++ acc, else: acc
        end
        if key in fields, do: to_mongo_id(value), else: value
    end


    # Ensure that returned map() record is the struct of the schema type.
    @spec cursor_record_to_struct(map(), mongo_schema) :: mongo_record
    defp cursor_record_to_struct(model, schema) do
        embed_keys = schema.__schema__(:embeds)
        model = for {key, val} <- model, into: %{} do
            atom_key = String.to_atom(key)
            if atom_key in embed_keys do
                embed_spec = schema.__schema__(:embed, atom_key)
                cursor_record_to_embed(atom_key, val, embed_spec)
            else
                case val do
                    %BSON.ObjectId{value: binary_id} ->
                        {atom_key, mongo_id_to_string(binary_id)}
                    %BSON.DateTime{utc: ts} ->
                        case schema.__schema__(:type, atom_key) do
                            Ecto.Date ->
                                {atom_key, timestamp_to_date(ts)}
                            _ ->
                                {atom_key, timestamp_to_datetime(ts)}
                        end
                    _ ->
                        {atom_key, val}
                end
            end
        end
        Kernel.struct(schema, model)
    end
    @spec cursor_record_to_struct(mongo_schema, map(), mongo_preload) :: mongo_record
    defp cursor_record_to_struct(schema, %{"_id" => %BSON.ObjectId{value: id}} = model, preload) do
        cursor_record_to_struct(schema, id, model, preload)
    end
    defp cursor_record_to_struct(schema, %{"_id" => id} = model, preload) do
        cursor_record_to_struct(schema, id, model, preload)
    end
    defp cursor_record_to_struct(schema, model, preload) do
        model
        |> cursor_record_to_struct(schema)
        |> preload(preload)
    end
    @spec cursor_record_to_struct(mongo_schema, String.t, map(), mongo_preload) :: mongo_record
    def cursor_record_to_struct(schema, id, model, preload) do
        if :id in schema.__schema__(:primary_key) do
            model
            |> Map.delete("_id")
            |> cursor_record_to_struct(schema)
            |> Map.put(:id, mongo_id_to_string(id))
            |> preload(preload)
        else
            model
            |> Map.delete("_id")
            |> cursor_record_to_struct(schema)
            |> preload(preload)
        end
    end
    

    # Convert mongo list or map to embedded schema
    @spec cursor_record_to_embed(atom(), map() | [map()], %Ecto.Embedded{}) :: {atom(), mongo_schema | [mongo_schema]}
    defp cursor_record_to_embed(key, vals, %Ecto.Embedded{
        cardinality: :many, 
        field: _owner_key,
        owner: _owner_schema,
        related: embedded_schema
    }) when is_list(vals) do
        embeds = Enum.map vals, &(cursor_record_to_struct(&1, embedded_schema))
        {key, embeds}
    end
    defp cursor_record_to_embed(key, %{} = val, %Ecto.Embedded{
        cardinality: :one, 
        field: _owner_key,
        owner: _owner_schema,
        related: embedded_schema
    }) do
        embed = cursor_record_to_struct(val, embedded_schema)
        {key, embed}
    end


    # Attach autogenerated primary key if it's required by schema.
    @spec add_autogenerated_field(Ecto.Schema.t, map(), mongo_record | mongo_id) :: map()
    defp add_autogenerated_field(schema, record, %{id: record_id}) do
        add_autogenerated_field(schema, record, record_id)
    end
    defp add_autogenerated_field(schema, record, value) do
        if schema.__schema__(:autogenerate_id) do
            [key | _] = schema.__schema__(:primary_key)
            Map.put(record, key, value)
        else
            record
        end
    end

    # Get field to add generic changeset error.
    @spec get_primary_error_field(Ecto.Schema.t) :: atom()
    defp get_primary_error_field(schema) do
        case schema.__schema__(:primary_key) do
            [] -> 
                [first_other_key | _] = schema.__schema__(:fields)
                first_other_key
            [first_primary_key | _] ->
                first_primary_key
        end
    end

    # Get query to match the record, first try to match by primary_keys.
    @spec get_record_query(mongo_record) :: map()
    defp get_record_query(%{__struct__: _schema, id: record_id}) do
        %{_id: to_mongo_id(record_id)}
    end
    defp get_record_query(%{__struct__: schema} = record) do
        keys = schema.__schema__(:primary_key)
        get_record_query(record, keys)
    end
    @spec get_record_query(mongo_record, [atom()]) :: map()
    defp get_record_query(%{__struct__: _schema} = record, keys) when length(keys) > 0 do
        Enum.reduce keys, %{}, fn(key, acc) ->
            value = to_mongo_id(Map.get(record, key))
            Map.put(acc, key, value)
        end
    end
    defp get_record_query(%{__struct__: schema} = record, _keys) do
        normalise_query_map(schema, Map.from_struct(record))
    end

    # Convert schema types to specific mongo type.
    @spec get_foreign_keys(mongo_record) :: [atom()]
    defp get_foreign_keys(%{__struct__: schema}) do
        schema.__schema__(:associations)|> Enum.reduce([], fn(assoc, acc) ->
            case schema.__schema__(:association, assoc) do
                %Ecto.Association.BelongsTo{owner_key: key} -> [key|acc]
                _ -> acc
            end
        end)
    end


    # Convert schema types to specific mongo types
    @spec convert_types_with(mongo_schema, fun()) :: mongo_schema
    defp convert_types_with(record, f) do
        record |> Map.new(fn({attr, val}) -> {attr, f.(val)} end)
    end


    # Convert specified types in schema to specific mongo types
    @spec convert_types_for(mongo_schema, [atom()], fun()) :: mongo_schema
    defp convert_types_for(record, fields, f) do
        Enum.reduce fields, record, fn(field, acc) ->
            Map.update!(acc, field, f)
        end
    end


    # Convert embedded documents to normal maps
    @spec convert_embeds(mongo_schema, [atom()]) :: mongo_schema
    defp convert_embeds(record, embed_keys) do
        Enum.reduce embed_keys, record, fn(embed_key, record) ->
            if Map.has_key?(record, embed_key) do
                embed = Map.fetch!(record, embed_key)
                Map.put record, embed_key, parse_embed(embed)
            else
                record
            end
        end
    end

    # Convert embeded schema to a Mongo serialisable object
    @spec parse_embed([map()] | map()) :: [map()] | map() | no_return
    defp parse_embed(embed) when is_list(embed) do
        Enum.map embed, &parse_embed/1
    end
    defp parse_embed(%{__struct__: schema} = embed) do
        assocs = schema.__schema__(:associations)
        embed
        |> Map.drop(assocs)
        |> Map.from_struct
    end
    defp parse_embed(%{} = embed) do
        embed
    end
    defp parse_embed(_) do
        raise Ecto.InvalidChangesetError
    end


    # Convert type to specific mongo type
    @spec to_mongo_type(any()) :: mongo_datatype
    defp to_mongo_type(%Ecto.Date{} = dt), do: ecto_date_to_mongo(dt)
    defp to_mongo_type(%Ecto.DateTime{} = dt), do: ecto_datetime_to_mongo(dt)
    defp to_mongo_type(type), do: type


    # Convert integer timestamp to %Ecto.Datetime{}
    @spec timestamp_to_datetime(integer()) :: %Ecto.DateTime{}
    defp timestamp_to_datetime(timestamp) do
        epoch = :calendar.datetime_to_gregorian_seconds({{1970, 1, 1}, {0, 0, 0}})
        datetime = :calendar.gregorian_seconds_to_datetime(epoch + div(timestamp, 1000))
        usec = rem(timestamp, 1000) * 1000
        %{Ecto.DateTime.from_erl(datetime) | usec: usec}
    end


    # Convert integer timestamp to %Ecto.Date{}
    @spec timestamp_to_date(integer()) :: %Ecto.Date{}
    defp timestamp_to_date(timestamp) do
        epoch = :calendar.datetime_to_gregorian_seconds({{1970, 1, 1}, {0, 0, 0}})
        {date, _} = :calendar.gregorian_seconds_to_datetime(epoch + div(timestamp, 1000))
        Ecto.Date.from_erl(date)
    end

    # Convert %Ecto.Date{} to BSON.DateTime object
    @spec ecto_date_to_mongo(%Ecto.Date{}) :: %BSON.DateTime{}
    defp ecto_date_to_mongo(ecto_timestamp = %Ecto.Date{}) do
        {:ok, date} = Ecto.Date.dump(ecto_timestamp)
        BSON.DateTime.from_datetime({date, {0, 0, 0, 0}})
    end

    # Convert %Ecto.Datetime{} to BSON.DateTime object
    @spec ecto_datetime_to_mongo(%Ecto.DateTime{}) :: %BSON.DateTime{}
    defp ecto_datetime_to_mongo(ecto_timestamp = %Ecto.DateTime{}) do
        {:ok, datetime} = Ecto.DateTime.dump(ecto_timestamp)
        BSON.DateTime.from_datetime(datetime)
    end
end
